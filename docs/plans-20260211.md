# LitScribe 实施计划

## 项目概述

LitScribe 是一个基于 MCP 和多智能体架构的自动文献综述引擎，实现从文献检索、批判性阅读到智能综述生成的全流程自动化。

**核心创新点**：
1. 混合 AI 策略：本地模型（Qwen 3）处理高频任务，Claude API 处理复杂综合
2. 多智能体协作：Discovery → Critical Reading → Synthesis → (Peer Review)
3. 可追溯引用系统：每个声明追溯到原文段落、PDF 页码
4. 本地优先缓存：SQLite 持久化，支持断点续跑和增量更新

---

## 已完成 ✅

### Iteration 1: MVP
MCP 服务器：arXiv, PubMed, Semantic Scholar, PDF Parser (pymupdf4llm/marker-pdf), Zotero
统一搜索聚合层（并行搜索、去重）+ CLI 工具

### Iteration 2: 多智能体系统
LangGraph 工作流：Discovery → Critical Reading → Synthesis
- Discovery: 查询扩展、多源搜索、论文筛选、雪球采样
- Critical Reading: PDF 解析、关键发现提取、方法论分析
- Synthesis: 主题识别、研究空白、综述生成
- CLI: `litscribe review "research question"`

---

## 已完成：Phase 6.5 - 缓存与持久化系统 ✅

SQLite 缓存层（`src/cache/`），本地优先搜索 + LangGraph checkpointing 断点续跑。
模块：database, paper_cache, pdf_cache, parse_cache, search_cache, cached_tools。DB 表：papers, pdfs, parsed_docs, search_cache, llm_cache, command_logs, failed_papers。

---

## 已完成：Phase 7 - 导出与多语言支持 ✅

**模块** (`src/exporters/`):
- `bibtex_exporter.py`: BibTeX 导出，自动生成 cite keys
- `pandoc_exporter.py`: Markdown → DOCX/PDF/HTML（需 Pandoc）
- `citation_formatter.py`: APA, MLA, Chicago, IEEE, GB/T 7714 格式

**CLI**: `litscribe export input.json --format docx --style APA --lang en`

---

## 已完成：Phase 7.5 - 规模化 + GraphRAG ✅

支持 50-500 篇论文的大规模文献综述，通过 GraphRAG 实现跨文档推理。

**GraphRAG 核心**（`src/graphrag/`）：entity_extractor → entity_linker → graph_builder → community_detector → summarizer → integration。
**Synthesis 集成**：社区直接转主题（`communities_to_themes()`），GraphRAG 增强综述生成，空社区自动回退。
**State 扩展**：`ExtractedEntity`, `Community`, `KnowledgeGraphData` 等类型。DB V3 迁移添加 entities/graph_edges/communities 表。
**CLI**：`--enable-graphrag` / `--disable-graphrag` / `--batch-size N`

---

## 已完成：Phase 8.6 - 综述直接多语言生成 ✅

在综述生成阶段直接用目标语言写作（非先英文后翻译）。

**方案**：Prompt 后缀注入 — `LANGUAGE_INSTRUCTIONS` 字典 + `get_language_instruction()` 函数，运行时追加到综述生成 prompt。JSON 结构化输出（themes/gaps）保持英文。
**涉及**：state.py (+language 字段), prompts.py, synthesis_agent.py, graph.py, litscribe_cli.py (`--lang`), user_config.py

---

## 已完成：Phase 8 - 智能搜索 + Zotero 增强 + 本地文件插入 ✅

搜索策略优化为本地优先、Zotero 双向增强、支持用户指定本地 PDF、用户配置持久化。

- **8.1 本地优先搜索**：SQLite 缓存 → Zotero 库 → 外部 API（仅查缺补漏）。涉及 cached_tools.py, discovery_agent.py, unified_search.py
- **8.2 PubMed 默认启用**：`create_initial_state()` 默认 sources 添加 `"pubmed"`
- **8.3 Zotero 深度集成**：Collection 管理、自动保存、批量导入、分析笔记回写。CLI: `--zotero-collection`
- **8.4 本地文件插入**：`--local-files` / `-f` 参数，本地 PDF 直接参与 review 工作流
- **8.5 用户配置文件**：`src/utils/user_config.py`，持久化到 `~/.litscribe/config.yaml`

---

## 已完成：Phase 9 - Self-Review + Planning + Refinement Agent ✅

三个质量控制 Agent 全部完成。

- **9.1 Self-Review Agent**（`src/agents/self_review_agent.py`）：synthesis 后自动评估质量（`ReviewAssessment`），覆盖度/论证/空白检查，低分 loop-back 回 discovery 补充搜索（最多3轮）
- **9.2 Planning Agent**（`src/agents/planning_agent.py`）：LLM 评估复杂度(1-5)，≥3 自动拆分子主题（`ResearchPlan`, `SubTopic`），CLI 交互确认（`--plan-only`, `--auto`），域感知检测（arXiv cats, S2 fields, PubMed MeSH）
- **9.3 Refinement Agent**（`src/agents/refinement_agent.py`）：自然语言指令解析 → 增量修改 review（add/remove/modify/rewrite），Git-like 版本管理（`src/versioning/review_versions.py`），DB v4 迁移添加 review_sessions/review_versions 表
- **CLI**：`litscribe session list/show/refine/diff/rollback`，review 后交互菜单

---

## 已完成：Emergency Fix - 搜索质量 + 分析深度 + 交互体验 大修 ✅

> 测试 alkaloid biosynthesis 综述时发现搜索污染（~30% 无关论文）、GraphRAG 污染、分析浅薄等严重问题

**7 步修复**（全部完成）：
1. **域感知 Query 扩展 + 搜索过滤** — Planning Agent 检测领域（arXiv categories, S2 fields, PubMed MeSH），Discovery 传域过滤参数，温度 0.7→0.4
2. **语义相关性评分** — 关键词匹配替代位置评分（title 0.4 + abstract 0.3 + keyword 0.2 + venue 0.1），fallback 改用 relevance_score 排序
3. **GraphRAG 相关性门控** — 过滤 relevance_score < 0.3 的论文，entity extraction 添加 research_question 上下文
4. **深度分析 + Self-Review 可操作化** — findings 3-5→5-8，LLM 打 relevance_to_question 分数，self-review 实际移除不相关论文，低分 loop-back
5. **语言不匹配检测** — 英文 query + `--lang zh` 弹出警告，中文 query 无 `--lang zh` 提示
6. **本地文件优先流程** — `--local-files` 先问是否联网，空 sources 跳过 discovery
7. **交互体验优化** — CLI 先调 planning + 确认，注入 plan 跳过 workflow 内 planning；review 后交互菜单（save/refine/show）；prompt 截断限制扩大

**涉及文件**: state.py, prompts.py, planning_agent.py, discovery_agent.py, unified_search.py, integration.py, entity_extractor.py, graphrag/prompts.py, critical_reading_agent.py, self_review_agent.py, supervisor.py, graph.py, litscribe_cli.py

---

## 已完成：Phase 9.5 - Evaluation & Instrumentation ✅

> AI 审稿人提出 7 项建议，核心是缺乏系统化评估和可复现性支撑。详细计划见 `docs/phase9.5_plan.md`

6 步全部完成：TokenTracker, Citation Grounding, ReviewEvaluator, Ablation Flags, Cross-Language Eval, Failure Analysis。
测试：3 新文件（46 tests）+ 2 更新文件，全部通过。

---

## 已完成：Phase 10 - MCP 架构重整 + GraphRAG 优化 ✅

> **目标**: 清理内部 MCP 装饰器，添加顶层 LitScribe MCP Server 供外部客户端使用；优化 GraphRAG 性能瓶颈
> **详细计划**: `docs/phase10_plan.md`

### 10.1 MCP 架构重整

**当前状态**: 5 个 MCP 文件共 38 个 `@mcp.tool()` 装饰器 + 5 个 `FastMCP()` 实例，但全部通过 `from mcp_servers.xxx import func` 直接调用，从未使用 MCP 协议。

**方案**: 内部去装饰器 + 外部包一层 MCP Server

| Step | 文件 | 操作 | 行数变化 |
|------|------|------|---------|
| 1 | `src/mcp_servers/arxiv_server.py` | 移除 7 个 `@mcp.tool()` + FastMCP + main() | -15 |
| 2 | `src/mcp_servers/pubmed_server.py` | 移除 7 个 `@mcp.tool()` + FastMCP + main() | -17 |
| 3 | `src/mcp_servers/pdf_parser_server.py` | 移除 6 个 `@mcp.tool()` + FastMCP + main() | -14 |
| 4 | `src/mcp_servers/semantic_scholar_server.py` | 移除 7 个 `@mcp.tool()` + FastMCP + main() | -15 |
| 5 | `src/mcp_servers/zotero_server.py` | 移除 11 个 `@mcp.tool()` + FastMCP + main() | -18 |
| 6 | `src/mcp_server.py` (NEW) | 统一 MCP Server：4 个高级工具 (search/review/paper/export)，支持 stdio + streamable-http | +150 |
| 7 | `pyproject.toml` | 添加 `litscribe-mcp` entry point | +1 |

**零功能影响**: 所有 `from mcp_servers.xxx import func` 导入路径不变，函数签名不变。

### 10.2 GraphRAG 优化

**决策变更**: 不引入 FAISS（100-1000 实体场景下 ROI 太低），改用 threshold + connected components 替代 AgglomerativeClustering。

| Step | 文件 | 优化 | 预期效果 |
|------|------|------|---------|
| 8 | `src/graphrag/entity_linker.py` | 替换 AgglomerativeClustering → threshold + `nx.connected_components()` | 代码更简洁，移除 sklearn 依赖 |
| 9 | `src/graphrag/entity_extractor.py` | 添加 JSON 解析重试（2 次，指数退避 1s/2s，温度 0.3→0.1） | 减少实体丢失 |
| 10 | `src/graphrag/summarizer.py` | `max_concurrent` 3→8 | 社区摘要提速 ~2.5x |
| 11 | `src/graphrag/graph_builder.py` | 优化 `_add_citation_edges()` 去除冗余年份分组循环 | 代码更清晰 |
| 12 | `tests/test_graphrag.py` | 添加 Test 9 (retry param) + Test 10 (threshold clustering) | 验证优化正确性 |

**提交顺序**:
1. `refactor(mcp): remove unused decorators from 5 server files` (Steps 1-5)
2. `feat(mcp): add unified MCP server for external clients` (Steps 6-7)
3. `perf(graphrag): replace AgglomerativeClustering with threshold connected components` (Step 8)
4. `feat(graphrag): add retry logic for entity extraction JSON parsing` (Step 9)
5. `perf(graphrag): increase summarizer concurrency, optimize citation edges` (Steps 10-11)
6. `test(graphrag): add tests for threshold clustering and retry` (Step 12)

**验证**: 运行全部 9 个测试文件（含 2 个新增 test）应全部通过

---

## 已完成：Emergency Fix #2 - CJK 字数统计 + 引用落地 + 来源统计 + 主题去重 ✅

> 测试中文（生物碱的生物合成）综述时发现 4 个 bug

**4 项修复**（全部完成，86/86 tests pass）：

1. **CJK 字数统计** — `len(text.split())` 对中文无效（4732 字报成 49）。新增 `count_words()` 函数，regex 分别统计 CJK 字符和 Latin 单词
2. **引用落地率 0%** — LLM 生成 `[Author, 2021]` 占位符而非真实作者姓。双管齐下：(a) prompts 明确要求使用真实作者姓，(b) `citation_grounding.py` 检测 generic name 并回退到年份匹配
3. **来源分布全零** — `UnifiedPaper` 使用 `sources: Dict[str, str]`（复数），而 discovery_agent 错用 `paper.get("source")`（单数）。改为从搜索结果的 `source_counts` 字典聚合
4. **主题重复** — `communities_to_themes()` 不同层级的社区产生同名主题。添加 name-based 去重

**涉及文件**: `synthesis_agent.py`（count_words + 主题去重）, `refinement_agent.py`（count_words）, `self_review_agent.py`（count_words）, `prompts.py`（引用格式指令 x5）, `citation_grounding.py`（generic name 回退）, `discovery_agent.py`（来源计数聚合）

---

## 已完成：Emergency Fix #3 - Resume 断点续跑 + Zotero 搜索接通 ✅

> resume 命令始终失败；Zotero 搜索代码存在但未正确接入工作流

**3 项修复**：

1. **Resume bug** — `graph.py:327` 传 `None` 给 `ainvoke()` 而非检查点状态，改为 `state_snapshot.values`
2. **Zotero source_counts 丢失** — `cached_tools.search_with_cache()` 未返回 `source_counts`，导致 discovery_agent 聚合为空。添加 `source_counts` 到返回值，discovery_agent 添加 zotero 计数回退
3. **CLI 文档** — help text 提示 Zotero 在已配置时自动搜索

**涉及文件**: `graph.py`, `cached_tools.py`, `discovery_agent.py`, `litscribe_cli.py`

**注**: Zotero 导出功能（`save_papers_to_zotero`, `write_analysis_to_zotero`）代码已写好但暂不接入工作流，作为可选功能留待后续

---

## Pre-Phase-11 Patch: 搜索质量 + Plan 迭代反馈

> **Context**: 测试中文综述（石杉碱甲的生物合成）时发现搜索结果包含大量无关论文（SARS-CoV-2、Toxoplasma 等），self_review relevance_score 仅 0.5。另外 plan 模式下选 N 直接退出，无法给 agent 反馈修改 plan。

### Patch A: 搜索质量改进（5 步）

| Step | 文件 | 改动 | 影响 |
|------|------|------|------|
| A1 | `src/aggregators/unified_search.py:171-174` | 关键词匹配改用 `re.search(r'\b...\b')` word boundary，不再用 substring `kw in text` | 防止 "bio" 匹配 "biography" 等误命中 |
| A1b | `src/agents/discovery_agent.py:349-350` | snowball 的 `_paper_matches_keywords` 同样改 word boundary | 同上 |
| A2 | `src/agents/discovery_agent.py:269` | `MIN_RELEVANCE` 从 0.25 → 0.35 | 过滤更多低分论文 |
| A3 | `src/agents/discovery_agent.py:398-433` | snowball `min_matches` 从固定 2 → 动态（keywords≥4 时要求 3） | snowball 引入的论文更相关 |
| A4 | `src/agents/critical_reading_agent.py:835-842` | **新增 pre-synthesis 过滤**：`relevance_to_question < 0.4` 的论文在 synthesis 前移除 | **最关键修复**——LLM 打分比关键词匹配准确得多 |
| A5 | `src/aggregators/unified_search.py:280-284` | PubMed MeSH 过滤改为 3+ 项时主 MeSH AND (次 OR 次)，不再纯 OR | 减少 PubMed 单 MeSH 误命中 |

#### A4 详细设计（最关键改动）

在 `critical_reading_agent()` 返回前（line 835 后），插入过滤逻辑：

```python
PRE_SYNTHESIS_MIN_RELEVANCE = 0.4
filtered_papers = [p for p in analyzed_papers if p.get("relevance_score", 0.5) >= PRE_SYNTHESIS_MIN_RELEVANCE]
removed = [p for p in analyzed_papers if p.get("relevance_score", 0.5) < PRE_SYNTHESIS_MIN_RELEVANCE]
# Log removed papers, append to errors for CLI visibility
analyzed_papers = filtered_papers
```

**阈值选择**：LLM 对 relevance 打分 0.0=完全无关 / 0.5=擦边 / 1.0=直接相关。0.4 移除明确无关的论文（如 SARS-CoV-2 会得 0.0-0.2），保留擦边的（0.45+）。

### Patch B: Plan 迭代反馈（4 步）

| Step | 文件 | 改动 |
|------|------|------|
| B1 | `src/agents/prompts.py` | 新增 `PLAN_REVISION_PROMPT`：接受原 plan JSON + 用户反馈 → 输出修改后的 plan |
| B2 | `src/agents/planning_agent.py` | 新增 `revise_plan(research_question, current_plan, user_feedback)` async 函数 |
| B3 | `src/cli/litscribe_cli.py:497-500` | 替换 `Y/n` 为反馈循环：Y=接受 / n=输入反馈→修改→重新展示 / q=退出 |
| B4 | （B3 内） | `MAX_PLAN_REVISIONS = 3`，防止无限循环 |

#### B3 流程设计

```
显示 plan → "Proceed? (Y/n/q):"
├─ Y/Enter → 接受 plan，继续
├─ q → "Review cancelled." 退出
├─ n → "What would you like to change?" → 输入反馈
│        → revise_plan() → 显示修改后的 plan → 重新询问
│        （最多 3 轮修改）
└─ 其他文本 → 直接作为反馈 → revise_plan()
```

### 测试新增

- `tests/test_search_quality.py`：新增 5 个 test（word boundary 正负例、hyphen、pre-synthesis filter 存在性、MeSH 逻辑）
- `tests/test_plan_override.py`：新增 4 个 test（revision prompt 存在、revise_plan 签名、CLI 反馈循环标志、MAX_PLAN_REVISIONS 范围）

### 实施顺序

1. A1 → A2 → A3 → A5 → A4（搜索质量，从简单到关键）
2. B1 → B2 → B3（plan 迭代，prompt → function → CLI）
3. 跑全部测试 `pytest tests/ -v`

### 验证

- 搜索质量：对 "石杉碱甲的生物合成" 重新跑 review，检查 self_review relevance_score 是否 > 0.7，检查是否还有明显无关论文
- Plan 迭代：手动测试 `litscribe review "complex topic"` → 选 n → 输入反馈 → 验证 plan 修改 → 选 Y 继续

---

## Phase 11: 本地 LLM 支持 (中优先级)

> **目标**: 支持多种本地 LLM 后端，降低 API 成本，提升隐私性，减少对外部服务的依赖

### 11.1 架构设计

**当前状态**: 项目通过 `litellm` 调用 LLM（`agents/tools.py` 的 `call_llm()`），已支持 Anthropic, DeepSeek 等云端 API。`litellm` 原生支持 Ollama。

**目标**: 支持 Ollama / MLX / vLLM 三种本地后端，用户可按任务类型配置不同模型。

**模型路由策略**:
| 任务类型 | 推荐模型 | 备选本地模型 |
|----------|----------|-------------|
| 查询扩展 | Haiku / 本地小模型 | Qwen3-8B (Ollama) |
| 论文分析 | Sonnet 4.5 / DeepSeek | Qwen3-32B (Ollama/MLX) |
| 实体抽取 | Sonnet 4.5 / 本地 | Qwen3-14B (Ollama) |
| 社区摘要 | Sonnet 4.5 / 本地 | Qwen3-32B |
| 综述生成 | Opus 4.5 / DeepSeek-R1 | 本地大模型或保持云端 |
| 批量处理 | DeepSeek / 本地 | Qwen3-8B (成本最低) |

### 11.2 实施步骤

1. **新建** `src/llm/`:
   - `router.py`: LLM 路由器
     - 根据任务类型 + 用户配置选择模型
     - 支持 fallback: 本地失败 → 自动回退云端
     - 支持并发限制（本地模型通常单线程）
   - `backends/ollama.py`: Ollama 集成
     - 通过 litellm 调用: `litellm.completion(model="ollama/qwen3:8b", ...)`
     - 自动检测 Ollama 是否运行 (`http://localhost:11434/api/tags`)
     - 模型拉取提示
   - `backends/mlx.py`: MLX 集成 (Apple Silicon 专用)
     - 使用 `mlx-lm` 库直接加载模型
     - 支持 4-bit/8-bit 量化
     - macOS 检测: 仅 Apple Silicon 可用
   - `backends/vllm.py`: vLLM 集成
     - OpenAI 兼容 API 模式
     - 通过 litellm: `litellm.completion(model="openai/model", api_base="http://localhost:8000")`
   - `config.py`: LLM 配置管理
     - 任务-模型映射关系
     - 后端优先级设置

2. **修改** `src/agents/tools.py`:
   - `call_llm()` 重构为使用 LLM 路由器
   - 添加 `task_type` 参数（query_expansion, paper_analysis, entity_extraction, synthesis 等）
   - 路由器根据 task_type 选择模型

3. **修改** `src/utils/user_config.py`:
   - 添加 LLM 配置部分:
   ```yaml
   llm:
     default_backend: "ollama"  # ollama | mlx | vllm | cloud
     task_models:
       query_expansion: "ollama/qwen3:8b"
       paper_analysis: "deepseek/deepseek-reasoner"
       entity_extraction: "ollama/qwen3:14b"
       synthesis: "anthropic/claude-opus-4-5"
     fallback_to_cloud: true
     ollama:
       base_url: "http://localhost:11434"
     mlx:
       model_path: "~/.cache/mlx-models/"
       quantization: "4bit"
     vllm:
       base_url: "http://localhost:8000"
   ```

4. **CLI 扩展**:
   ```bash
   litscribe config llm                    # 查看当前 LLM 配置
   litscribe config llm --backend ollama   # 切换默认后端
   litscribe review "topic" --model ollama/qwen3:32b  # 临时指定模型
   ```

5. **新增依赖** (pyproject.toml, optional):
   - `mlx-lm` (extras: mlx)
   - `vllm` (extras: vllm)
   - Ollama 不需要额外 Python 依赖（通过 litellm HTTP 调用）

### 11.3 验证
- Ollama: 启动 Ollama → `litscribe review "test" --model ollama/qwen3:8b`
- MLX: `litscribe review "test" --model mlx/qwen3-8b-4bit`
- Fallback: 关闭 Ollama → 验证自动回退到云端

---

## Phase 12: 订阅系统 + 每日热点推送 (中优先级)

> (原 Phase 11)

> **目标**: 用户订阅关键词，系统定时搜索新论文，生成摘要推送；累积足够新文章时提示生成 review

### 12.1 订阅管理

**数据库扩展** (`src/cache/database.py`, Schema v5):
```sql
CREATE TABLE subscriptions (
    id INTEGER PRIMARY KEY,
    keywords TEXT,           -- JSON array of keywords
    sources TEXT,            -- JSON array: ["arxiv", "pubmed", "semantic_scholar"]
    frequency TEXT,          -- "daily" | "weekly"
    notify_methods TEXT,     -- JSON array: ["email", "webhook", "web"]
    auto_review_threshold INTEGER DEFAULT 20,  -- 累积几篇后提示生成 review
    last_run_at TIMESTAMP,
    is_active BOOLEAN DEFAULT TRUE,
    created_at TIMESTAMP
);

CREATE TABLE subscription_papers (
    id INTEGER PRIMARY KEY,
    subscription_id INTEGER REFERENCES subscriptions(id),
    paper_id TEXT,
    discovered_at TIMESTAMP,
    is_new BOOLEAN DEFAULT TRUE
);

CREATE TABLE notifications (
    id INTEGER PRIMARY KEY,
    subscription_id INTEGER,
    type TEXT,               -- "digest" | "review_suggestion"
    content TEXT,            -- JSON: summary, paper_count, etc.
    delivered_methods TEXT,  -- JSON: which methods succeeded
    created_at TIMESTAMP
);
```

### 12.2 定时抓取

**新建** `src/subscriptions/`:
- `manager.py`: 订阅 CRUD 操作
- `scheduler.py`: 定时任务调度
  - 使用 `APScheduler` 的 `AsyncIOScheduler`
  - 每日检查所有 active subscriptions
  - 调用现有 `unified_search()` 搜索新论文（利用 `reldate` / `sortBy` 参数筛选最新）
  - 去重后存入 `subscription_papers`
- `digest_generator.py`: 使用 LLM 对新论文生成每日摘要
- `auto_review_detector.py`: 检测是否累积够阈值，生成 review 建议通知

### 12.3 通知系统

**新建** `src/notifications/`:
- `base.py`: `NotificationAdapter` 抽象基类
- `email_adapter.py`: SMTP 邮件推送（支持 HTML 格式摘要）
- `webhook_adapter.py`: HTTP POST webhook（对接 Slack, Discord, 飞书等）
- `web_adapter.py`: 存入数据库，供 Web UI 轮询/WebSocket 推送

**配置**: 通过 `~/.litscribe/config.yaml` 配置 SMTP、webhook URL 等

### 12.4 CLI 扩展
```bash
litscribe subscribe "LLM reasoning" --sources arxiv,pubmed --frequency daily
litscribe subscribe list
litscribe subscribe pause <id>
litscribe subscribe digest <id>    # 手动触发摘要
```

---

## Phase 13: React + FastAPI Web UI (中优先级)

> **目标**: 提供完整的 Web 界面，支持 session 管理、实时进度、review 编辑、订阅通知

### 13.1 架构
```
┌─────────────────────────────────────────────────┐
│                   Frontend                       │
│  React + TailwindCSS + shadcn/ui                │
│  - Dashboard: 概览 + 订阅通知                    │
│  - Sessions: Session CRUD + 版本对比             │
│  - Review Editor: Markdown 编辑 + 迭代续写       │
│  - Knowledge Graph: 交互式知识图谱               │
│  - Subscriptions: 订阅管理 + 摘要查看            │
└─────────────────────────────────────────────────┘
                      ↓ REST / WebSocket
┌─────────────────────────────────────────────────┐
│              FastAPI Backend                     │
│  - /api/sessions     - Session CRUD + versions  │
│  - /api/reviews      - 启动/查询/迭代 Review    │
│  - /api/subscriptions - 订阅 CRUD               │
│  - /api/notifications - 通知列表                │
│  - /api/cache        - 缓存统计                 │
│  - /ws/progress      - 实时进度推送 (WebSocket)  │
└─────────────────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────┐
│           LitScribe Core (现有)                  │
│  Agents + GraphRAG + Cache + Subscriptions       │
└─────────────────────────────────────────────────┘
```

### 13.2 关键文件
```
src/api/
├── main.py               # FastAPI app, CORS, middleware
├── dependencies.py        # 依赖注入
├── routers/
│   ├── sessions.py        # Session CRUD + version management
│   ├── reviews.py         # Review 启动/状态查询/迭代
│   ├── subscriptions.py   # 订阅管理
│   ├── notifications.py   # 通知查询
│   └── cache.py           # 缓存统计/管理
└── websocket.py           # WebSocket 实时进度

web/
├── package.json
├── src/
│   ├── App.tsx
│   ├── pages/
│   │   ├── Dashboard.tsx       # 概览 + 最新通知
│   │   ├── Sessions.tsx        # Session 列表
│   │   ├── SessionDetail.tsx   # 单个 session + 版本历史
│   │   ├── ReviewEditor.tsx    # Markdown review 编辑/续写
│   │   ├── KnowledgeGraph.tsx  # 知识图谱可视化
│   │   └── Subscriptions.tsx   # 订阅管理
│   ├── components/
│   │   ├── ProgressStream.tsx  # WebSocket 进度条
│   │   ├── DiffViewer.tsx      # 版本对比组件
│   │   └── NotificationBell.tsx
│   └── hooks/
│       ├── useWebSocket.ts
│       └── useReview.ts
```

### 13.3 关键实现
- **实时进度**: 利用已有的 `run_with_streaming()` (graph.py:292)，通过 WebSocket 推送每个 agent 节点的进度
- **Session 续写 UI**: Review Editor 底部输入框，用户输入指令 → 调用 Refinement Agent → 实时显示修改
- **版本对比**: 使用 diff 算法在前端高亮显示变更（类似 GitHub diff view）

---

## Phase 14: 可视化系统 (中低优先级)

> **目标**: 程序化图表 + Nano Banana AI 信息图，为 review 提供丰富的视觉内容

### 14.1 程序化图表

**新建** `src/visualization/`:

| 模块 | 功能 | 库 |
|------|------|----|
| `knowledge_graph_viz.py` | 交互式知识图谱 | pyvis |
| `trend_charts.py` | 论文趋势、引用分布 | plotly |
| `heatmaps.py` | 主题-方法矩阵、时间热力图 | seaborn + matplotlib |
| `network_viz.py` | 引用关系网络 | pyvis / plotly |

**输出**: HTML (交互式) 或 PNG/SVG (静态)，嵌入到 review 或 Web UI

**数据来源**: 复用 `graphrag/graph_builder.py` 的 NetworkX 图 + `community_detector.py` 的社区数据

### 14.2 Nano Banana AI 信息图

**集成 Google Gemini Image API** (Gemini 2.5 Flash Image / Gemini 3 Pro Image)

**新建** `src/visualization/nano_banana.py`:
- `generate_knowledge_map(graph_data, style)` — 知识图谱信息图
- `generate_trend_infographic(papers, topic)` — 研究趋势可视化
- `generate_review_summary_image(review_text, themes)` — Review 摘要图

**工作流**: 从 GraphRAG 数据 + Review 文本中提取结构化描述 → 构造 Gemini Image prompt → 生成图片 → 添加 SynthID 水印标识

**配置**: `GOOGLE_API_KEY` in `.env`, 模型选择 (flash/pro)

**CLI**:
```bash
litscribe visualize review.json --type knowledge-graph --output graph.html
litscribe visualize review.json --type heatmap --output heatmap.png
litscribe visualize review.json --type infographic --engine nano-banana
```

---

## Phase 15: 微信公众号搜索 + 附加功能 (低优先级)

### 15.1 微信公众号搜索 (实验性)
**难度**: 高 | **风险**: 高（无官方 API）

**方案评估**:
| 方案 | 稳定性 | 成本 | 推荐 |
|------|--------|------|------|
| 搜狗微信搜索爬虫 | 低（反爬） | 免费 | 先试试 |
| RSSHub 微信订阅 | 中 | 免费 | 特定公众号 |
| NewRank / 清博 API | 高 | 付费 | 生产环境 |

**新建** `src/mcp_servers/wechat_server.py`:
- `search_wechat_articles(query, limit)` — 搜索微信公众号文章
- `get_article_content(url)` — 获取文章正文
- 标记为实验性功能，默认不启用

### 15.2 成本追踪 → 已移至 Phase 9.5 Step 1 ✅
> 原计划在此实现，现已提前至 Phase 9.5（审稿建议 #6）

### 15.3 自动化测试
**新建** `tests/`:
- `test_search.py` — 搜索 + 去重 + 缓存测试
- `test_agents.py` — Agent 工作流测试（mock LLM）
- `test_graphrag.py` — GraphRAG pipeline 测试
- `test_export.py` — 导出格式测试
- `test_versioning.py` — Review 版本管理测试

### 15.4 其他学术数据源 (远期)
- Google Scholar（需代理/爬虫）
- DBLP（计算机领域，有 API）
- IEEE Xplore / Web of Science（需订阅）

---

## 规划中（远期）

### 高级功能
- 多智能体辩论机制（处理矛盾文献）
- 引用追溯系统（声明 → 段落 → PDF 页码）
- 幻觉检测与缓解（基于 GraphRAG 交叉验证）
- 本地 LLM 优化（MLX）
- 多用户支持（做 Web UI 时再议）

---

## 技术决策记录

### 存储方案
| 方案 | 优点 | 缺点 | 决策 |
|------|------|------|------|
| SQLite | 零依赖、便携、ACID | 单写入者 | ✅ 选用 |
| JSON 文件 | 简单 | 无查询能力 | ❌ |
| DuckDB | 分析查询快 | 额外依赖 | ❌ |

### PDF 解析后端
| 后端 | 速度 | OCR | 稳定性 | 决策 |
|------|------|-----|--------|------|
| pymupdf4llm | 快 | 否 | 稳定 | ✅ 默认 |
| marker-pdf | 慢 | 是 | macOS MPS 不稳定 | 备选 |

### LLM 调用策略
| 任务 | 模型 | 理由 |
|------|------|------|
| 查询扩展 | Claude Haiku / 本地 | 简单任务，低成本 |
| 论文分析 | Claude Sonnet 4.5 | 平衡质量与成本 |
| 综述生成 | Claude Opus 4.5 | 复杂综合任务 |
| 大规模分析 | DeepSeek-R1 | 成本低，适合批量 |

### 速率限制
| API | 限制 | 缓解措施 |
|-----|------|---------|
| Semantic Scholar | 1 req/s | AsyncRateLimiter |
| PubMed | 3 req/s (无 key) | 缓存 + 批量请求 |
| arXiv | 无明确限制 | 礼貌性延迟 |

---

## 项目结构（当前）

```
LitScribe/
├── src/
│   ├── services/             # API 客户端库 ✅ (Phase 10 renamed from mcp_servers/)
│   │   ├── arxiv.py
│   │   ├── pubmed.py
│   │   ├── semantic_scholar.py
│   │   ├── pdf_parser.py
│   │   └── zotero.py
│   │
│   ├── mcp_server.py          # 统一 MCP Server (Phase 10)
│   │
│   ├── agents/               # 多智能体系统 ✅
│   │   ├── state.py          # GraphRAG 类型定义
│   │   ├── graph.py          # LangGraph 工作流
│   │   ├── supervisor.py     # 路由逻辑
│   │   ├── discovery_agent.py
│   │   ├── critical_reading_agent.py
│   │   ├── synthesis_agent.py  # GraphRAG 深度集成
│   │   ├── tools.py
│   │   ├── errors.py
│   │   └── prompts.py
│   │
│   ├── graphrag/             # GraphRAG 核心 ✅
│   │   ├── entity_extractor.py
│   │   ├── entity_linker.py
│   │   ├── graph_builder.py
│   │   ├── community_detector.py
│   │   ├── summarizer.py
│   │   ├── prompts.py
│   │   └── integration.py
│   │
│   ├── aggregators/          # 搜索聚合 ✅
│   │   └── unified_search.py
│   │
│   ├── cache/                # 缓存系统 ✅
│   │   ├── database.py
│   │   ├── paper_cache.py
│   │   ├── search_cache.py
│   │   ├── pdf_cache.py
│   │   ├── parse_cache.py
│   │   ├── graphrag_cache.py
│   │   ├── failed_papers.py
│   │   └── cached_tools.py
│   │
│   ├── exporters/            # 导出功能 ✅
│   │   ├── bibtex_exporter.py
│   │   ├── pandoc_exporter.py
│   │   └── citation_formatter.py
│   │
│   ├── analysis/             # 评估与分析 ✅ (Phase 9.5)
│   │   ├── citation_grounding.py
│   │   ├── review_evaluator.py
│   │   └── failure_analysis.py
│   │
│   ├── utils/                # 工具模块 ✅
│   │   ├── token_tracker.py
│   │   └── user_config.py
│   │
│   ├── versioning/           # Review 版本管理 ✅ (Phase 9.3)
│   │   └── review_versions.py
│   │
│   └── cli/
│       ├── litscribe_cli.py
│       └── output.py
│
├── output/                   # 综述输出
├── data/                     # PDF 存储
└── cache/                    # SQLite 数据库
```

---

## 参考资料

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [FastMCP 2.0](https://github.com/jlowin/fastmcp)
- [claude-scientific-writer](https://github.com/K-Dense-AI/claude-scientific-writer) - 借鉴引用管理和 Peer Review
- [Qwen 3 GitHub](https://github.com/QwenLM/Qwen3)
